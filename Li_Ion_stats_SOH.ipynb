{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO_gwtC0V1gl"
      },
      "source": [
        "## Authors: Hardik Chhabra, Kartik Sahajpal\n",
        "##### Licensed under MIT License"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P6BVHMHVmLY",
        "outputId": "59355cf6-fde2-4d85-af6c-be1aec31c51d"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX-ZHxAuV24U"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ab0hd5KVRE_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "import statistics\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import optuna\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LogNorm\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import os, math\n",
        "from optuna.importance import get_param_importances\n",
        "import pickle\n",
        "from scipy.stats import skew, kurtosis\n",
        "import joblib\n",
        "import warnings\n",
        "from torch import nn\n",
        "import plotly\n",
        "import time\n",
        "from optuna.visualization import plot_optimization_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXs4jp7nWkNu"
      },
      "source": [
        "**getAvaiableDevice:** try to allocate GPU, if not GPU then fall back to CPU resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT-gbsOjWkic"
      },
      "outputs": [],
      "source": [
        "def getAvailableDevice(index=0):\n",
        "    \"\"\"\n",
        "    Returns a CUDA device if available at the given index;\n",
        "    otherwise falls back to CPU.\n",
        "    \"\"\"\n",
        "    if torch.cuda.device_count() > index:\n",
        "        return torch.device(f\"cuda:{index}\")\n",
        "    return torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRMzAxJwV6G8"
      },
      "source": [
        "**computeMAPE:** computes MAPE for predicted and true data.\n",
        "\n",
        "**computeRMSE:** computes RMSE for predicted and true data.\n",
        "\n",
        "**computeR2Score:** computes R2 score for predicted and true data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqC01MqIVuDY"
      },
      "outputs": [],
      "source": [
        "def computeMAPE(predictions, targets):\n",
        "    \"\"\"\n",
        "    Computes Mean Absolute Percentage Error (MAPE).\n",
        "\n",
        "    Args:\n",
        "        predictions (Tensor): Model outputs\n",
        "        targets (Tensor): Ground truth values\n",
        "\n",
        "    Returns:\n",
        "        Tensor: MAPE value\n",
        "    \"\"\"\n",
        "    percentageError = torch.abs((predictions - targets) / targets)\n",
        "    return torch.sum(percentageError) / targets.numel()\n",
        "\n",
        "\n",
        "def computeRMSE(predictions, targets):\n",
        "    \"\"\"\n",
        "    Computes Root Mean Squared Error (RMSE).\n",
        "\n",
        "    Args:\n",
        "        predictions (Tensor): Model outputs\n",
        "        targets (Tensor): Ground truth values\n",
        "\n",
        "    Returns:\n",
        "        Tensor: RMSE value\n",
        "    \"\"\"\n",
        "    squaredError = (predictions - targets) ** 2\n",
        "    meanSquaredError = torch.sum(squaredError) / targets.numel()\n",
        "    return torch.sqrt(meanSquaredError)\n",
        "\n",
        "\n",
        "def computeR2Score(predictions, targets):\n",
        "    \"\"\"\n",
        "    Computes the R-squared (coefficient of determination).\n",
        "\n",
        "    Args:\n",
        "        predictions (Tensor): Model outputs\n",
        "        targets (Tensor): Ground truth values\n",
        "\n",
        "    Returns:\n",
        "        Tensor: R² score\n",
        "    \"\"\"\n",
        "    targetMean = torch.mean(targets)\n",
        "    residualSum = torch.sum((predictions - targets) ** 2)\n",
        "    totalSum = torch.sum((targets - targetMean) ** 2)\n",
        "    return 1 - (residualSum / totalSum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkX_fdOJXbrz"
      },
      "source": [
        "**buildKFoldSplit:** Creates training and validation subsets for k-fold cross-validation when input features include an additional dimension.\n",
        "\n",
        "**readDatasetFiles:** Loads battery datasets from Excel files, cleans voltage sequences, segments cycles, and organizes them into a structured dictionary.\n",
        "\n",
        "**createDataLoaders:** Converts training and testing tensors into PyTorch DataLoader objects with batching and shuffling.\n",
        "\n",
        "**transposeFeatureTensor:** Rearranges a three-dimensional tensor by swapping its first and second axes.\n",
        "\n",
        "**generateBatches:** Iterates over a tensor and yields fixed-size mini-batches for efficient processing.\n",
        "\n",
        "**splitCells:** Divides data into training and testing sets based on cell identifiers.\n",
        "\n",
        "**splitCellsWithStats:** Extracts statistical voltage features (mean, standard deviation, minimum, maximum) and splits the data by cell identifiers.\n",
        "\n",
        "**scaleFeatureData:** Normalizes feature tensors using predefined voltage bounds across training and testing data.\n",
        "\n",
        "**scaleRawVoltageData:** Normalizes raw voltage tensors for both training and testing datasets using fixed voltage limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYIeMW3aXcCL"
      },
      "outputs": [],
      "source": [
        "def buildKFoldSplit(kFolds, foldIndex, features, targets):\n",
        "    \"\"\"\n",
        "    Generates training and validation splits for k-fold cross validation\n",
        "    when feature tensors contain an extra dimension.\n",
        "    \"\"\"\n",
        "    if kFolds <= 1:\n",
        "        raise ValueError(\"k-fold validation requires k > 1\")\n",
        "\n",
        "    foldLength = features.shape[1] // kFolds\n",
        "    trainX, trainY = None, None\n",
        "\n",
        "    for fold in range(kFolds):\n",
        "        sliceIdx = slice(fold * foldLength, (fold + 1) * foldLength)\n",
        "        xSlice = features[:, sliceIdx, :]\n",
        "        ySlice = targets[sliceIdx]\n",
        "\n",
        "        if fold == foldIndex:\n",
        "            valX, valY = xSlice, ySlice\n",
        "        else:\n",
        "            if trainX is None:\n",
        "                trainX, trainY = xSlice, ySlice\n",
        "            else:\n",
        "                trainX = torch.cat((trainX, xSlice), dim=1)\n",
        "                trainY = torch.cat((trainY, ySlice), dim=0)\n",
        "\n",
        "    return trainX, trainY, valX, valY\n",
        "\n",
        "\n",
        "def readDatasetFiles(targetFiles, datasetIndex=-1):\n",
        "    \"\"\"\n",
        "    Loads and processes battery datasets from Excel files.\n",
        "    \"\"\"\n",
        "    baseDir = \"/content/dataset2/\"\n",
        "    outputData = {}\n",
        "\n",
        "    for fileIdx, file in enumerate(os.listdir(baseDir)):\n",
        "        if file not in targetFiles:\n",
        "            continue\n",
        "\n",
        "        filePath = os.path.join(baseDir, file)\n",
        "        table = pd.read_excel(filePath)\n",
        "\n",
        "        lastCycle = 0\n",
        "        segmentCount = 0\n",
        "        buffer = []\n",
        "        totalRows = len(table)\n",
        "\n",
        "        for row in range(totalRows):\n",
        "            cycleNum = table.loc[row, \"cycle\"]\n",
        "            capacityNorm = table.loc[row, \"Capacity\"] / 3500\n",
        "            voltageStr = table.loc[row, \"Voltages\"].replace(\"\\n\", \"\")[1:-1].split(\" \")\n",
        "            voltageStr = [v for v in voltageStr if v != \"\"]\n",
        "            voltageArr = np.array(list(map(float, voltageStr)))\n",
        "\n",
        "            if (\n",
        "                voltageArr[-1] < 4.1\n",
        "                or any(np.diff(voltageArr) > 0.001)\n",
        "                or any(np.diff(voltageArr, n=2) < -0.001)\n",
        "            ):\n",
        "                continue\n",
        "\n",
        "            if cycleNum < lastCycle or row == totalRows - 1:\n",
        "                segmentCount += 1\n",
        "                rate = table.loc[row - 1, \"rate\"]\n",
        "                temp = table.loc[row - 1, \"Tem\"]\n",
        "                keyName = f\"D{fileIdx+1}{rate}{temp}_{segmentCount}\"\n",
        "\n",
        "                outputData[keyName] = {\n",
        "                    \"cycle\": np.array([item[0] for item in buffer]),\n",
        "                    \"V\": np.stack([item[1] for item in buffer]),\n",
        "                    \"Q\": np.array([item[2] for item in buffer]),\n",
        "                }\n",
        "                buffer = []\n",
        "\n",
        "            lastCycle = cycleNum\n",
        "            buffer.append([cycleNum, voltageArr, capacityNorm])\n",
        "\n",
        "    return outputData\n",
        "\n",
        "\n",
        "def createDataLoaders(trainX, trainY, testX, testY, batchSize):\n",
        "    \"\"\"\n",
        "    Wraps tensors into PyTorch DataLoader objects.\n",
        "    \"\"\"\n",
        "    trainingSet = TensorDataset(trainX, trainY)\n",
        "    testingSet = TensorDataset(testX, testY)\n",
        "\n",
        "    trainLoader = DataLoader(trainingSet, batch_size=batchSize, shuffle=True)\n",
        "    testLoader = DataLoader(testingSet, batch_size=batchSize, shuffle=True)\n",
        "\n",
        "    return trainLoader, testLoader\n",
        "\n",
        "\n",
        "def transposeFeatureTensor(tensorInput):\n",
        "    \"\"\"\n",
        "    Rearranges a 3D tensor by swapping the first two dimensions.\n",
        "    \"\"\"\n",
        "    dimA, dimB, dimC = tensorInput.shape\n",
        "    outputArray = np.empty((dimB, dimA, dimC))\n",
        "\n",
        "    for b in range(dimB):\n",
        "        for a in range(dimA):\n",
        "            outputArray[b, a] = tensorInput[a, b]\n",
        "\n",
        "    return torch.tensor(outputArray, dtype=torch.float64)\n",
        "\n",
        "\n",
        "def generateBatches(dataTensor, batchSize=1024):\n",
        "    \"\"\"\n",
        "    Iterates over a tensor in fixed-size batches.\n",
        "    \"\"\"\n",
        "    totalLength = dataTensor.shape[0]\n",
        "    for start in range(0, totalLength, batchSize):\n",
        "        yield dataTensor[start : start + batchSize]\n",
        "\n",
        "\n",
        "def splitCells(dataDictionary, testCellIds=None, trainCellIds=None):\n",
        "    \"\"\"\n",
        "    Separates data into training and testing sets based on cell identifiers.\n",
        "    \"\"\"\n",
        "    useTrainIds = trainCellIds is not None\n",
        "    selectedIds = trainCellIds if useTrainIds else testCellIds\n",
        "\n",
        "    trainX, trainY, testX, testY = {}, {}, {}, {}\n",
        "\n",
        "    for key, entry in dataDictionary.items():\n",
        "        cellNumber = int(key.split(\"_\")[-1])\n",
        "\n",
        "        assignToTest = (cellNumber in selectedIds) ^ useTrainIds\n",
        "        voltageTensor = torch.tensor(entry[\"V\"], dtype=torch.float32)\n",
        "        cycleTensor = torch.tensor(entry[\"cycle\"], dtype=torch.float32)\n",
        "\n",
        "        if assignToTest:\n",
        "            testX[key], testY[key] = voltageTensor, cycleTensor\n",
        "        else:\n",
        "            trainX[key], trainY[key] = voltageTensor, cycleTensor\n",
        "\n",
        "    return trainX, trainY, testX, testY\n",
        "\n",
        "\n",
        "def splitCellsWithStats(dataDictionary, testCellIds=None, trainCellIds=None):\n",
        "    \"\"\"\n",
        "    Extracts statistical voltage features and splits data by cell.\n",
        "    \"\"\"\n",
        "    useTrainIds = trainCellIds is not None\n",
        "    selectedIds = trainCellIds if useTrainIds else testCellIds\n",
        "\n",
        "    trainX, trainY, testX, testY = {}, {}, {}, {}\n",
        "\n",
        "    for key, entry in dataDictionary.items():\n",
        "        means, stds, mins, maxs = [], [], [], []\n",
        "\n",
        "        for v in entry[\"V\"]:\n",
        "            means.append(statistics.mean(v))\n",
        "            stds.append(statistics.stdev(v))\n",
        "            mins.append(min(v))\n",
        "            maxs.append(max(v))\n",
        "\n",
        "        means = np.array(means)\n",
        "        stds = np.array(stds)\n",
        "        mins = np.array(mins)\n",
        "        maxs = np.array(maxs)\n",
        "\n",
        "        seqLen = len(entry[\"V\"][0])\n",
        "        meanMat = np.tile(means[:, None], (1, seqLen))\n",
        "        stdMat = np.tile(stds[:, None], (1, seqLen))\n",
        "        minMat = np.tile(mins[:, None], (1, seqLen))\n",
        "        maxMat = np.tile(maxs[:, None], (1, seqLen))\n",
        "\n",
        "        featureTensor = torch.tensor(\n",
        "            [minMat, meanMat, maxMat, stdMat], dtype=torch.float32\n",
        "        )\n",
        "        labelTensor = torch.tensor(entry[\"Q\"], dtype=torch.float32)\n",
        "\n",
        "        cellNumber = int(key.split(\"_\")[-1])\n",
        "        assignToTest = (cellNumber in selectedIds) ^ useTrainIds\n",
        "\n",
        "        if assignToTest:\n",
        "            testX[key], testY[key] = featureTensor, labelTensor\n",
        "        else:\n",
        "            trainX[key], trainY[key] = featureTensor, labelTensor\n",
        "\n",
        "    return trainX, trainY, testX, testY\n",
        "\n",
        "\n",
        "def scaleFeatureData(trainMap, testMap):\n",
        "    \"\"\"\n",
        "    Normalizes feature tensors using fixed voltage bounds.\n",
        "    \"\"\"\n",
        "    trainStack = torch.concat(list(trainMap.values()), dim=1)\n",
        "    testStack = torch.concat(list(testMap.values()), dim=1)\n",
        "\n",
        "    upperBound = torch.tensor(4.2)\n",
        "    lowerBound = torch.tensor(4.1)\n",
        "\n",
        "    trainNorm = (trainStack - lowerBound) / (upperBound - lowerBound)\n",
        "    testNorm = (testStack - lowerBound) / (upperBound - lowerBound)\n",
        "\n",
        "    for key in testMap:\n",
        "        testMap[key] = (testMap[key] - lowerBound) / (upperBound - lowerBound)\n",
        "\n",
        "    return trainNorm, testNorm\n",
        "\n",
        "\n",
        "def scaleRawVoltageData(trainMap, testMap):\n",
        "    \"\"\"\n",
        "    Normalizes raw voltage values across training and testing sets.\n",
        "    \"\"\"\n",
        "    trainStack = torch.concat(list(trainMap.values()))\n",
        "    testStack = torch.concat(list(testMap.values()))\n",
        "\n",
        "    upperBound = torch.tensor(4.2)\n",
        "    lowerBound = torch.tensor(4.1)\n",
        "\n",
        "    trainNorm = (trainStack - lowerBound) / (upperBound - lowerBound)\n",
        "    testNorm = (testStack - lowerBound) / (upperBound - lowerBound)\n",
        "\n",
        "    for key in testMap:\n",
        "        testMap[key] = (testMap[key] - lowerBound) / (upperBound - lowerBound)\n",
        "\n",
        "    return trainNorm, testNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8biWjuuZfCY"
      },
      "source": [
        "## CNN Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmug4Xh_ZfUQ"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, dropout=0.001, **kwargs):\n",
        "        super(CNNModel, self).__init__(**kwargs)\n",
        "        self.conv_layers = nn.Sequential(\n",
        "                nn.Conv1d(4, 16, 3, padding=1), nn.ReLU(), nn.BatchNorm1d(16), # Set first argument of this nn.conv1d to number of features used\n",
        "                nn.Conv1d(16, 16, 3, padding=1), nn.ReLU(), nn.BatchNorm1d(16),\n",
        "                nn.Conv1d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool1d(2, stride=2), nn.BatchNorm1d(32),\n",
        "                nn.Conv1d(32, 32, 3, padding=1), nn.ReLU(), nn.BatchNorm1d(32),\n",
        "                nn.Conv1d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool1d(2, stride=2), nn.BatchNorm1d(64),\n",
        "                nn.Conv1d(64, 64, 3, padding=1), nn.ReLU(), nn.BatchNorm1d(64),\n",
        "                nn.Conv1d(64, 64, 3, padding=1), nn.ReLU(), nn.BatchNorm1d(64)\n",
        "        )\n",
        "\n",
        "        self.lstm_layer = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True)\n",
        "        self.gru_layer = nn.GRU(input_size=64, hidden_size=64, num_layers=1, batch_first=True)\n",
        "        self.birnn_layer = nn.RNN(input_size=64, hidden_size=64, num_layers=1, batch_first=True, bidirectional=True)\n",
        "        self.final_conv = nn.Sequential(\n",
        "            nn.Conv1d(64, 64, 3, padding = 1), nn.ReLU(), nn.BatchNorm1d(64) # Change 64 to nn.Conv1d(128, ..) for Bidirectional layer\n",
        "        )\n",
        "\n",
        "        self.flatten_layer = nn.Flatten()\n",
        "        self.fc1 = nn.Sequential(nn.Dropout(dropout), nn.Linear(3 * 64, 32), nn.ReLU())\n",
        "        self.fc2 = nn.Sequential(nn.Dropout(dropout), nn.Linear(32, 1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        inputs = inputs.float()\n",
        "        conv_output = self.conv_layers(inputs)\n",
        "        conv_output = conv_output.permute(0, 2, 1)\n",
        "        conv_output, _ = self.lstm_layer(conv_output) # Change the layer as per experiment\n",
        "        conv_output = conv_output.permute(0, 2, 1)\n",
        "        conv_output = self.final_conv(conv_output)\n",
        "\n",
        "        conv_output = self.flatten_layer(conv_output)\n",
        "        fc_output = self.fc1(conv_output)\n",
        "        fc_output = self.fc2(fc_output)\n",
        "        return torch.squeeze(fc_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLh8xd9_Z3WI"
      },
      "source": [
        "Train model function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3Vwtr_VZoKH"
      },
      "outputs": [],
      "source": [
        "def trainNeuralNetwork(\n",
        "    network,\n",
        "    trainFeatures,\n",
        "    trainTargets,\n",
        "    testFeatures,\n",
        "    testTargets,\n",
        "    numEpochs,\n",
        "    learningRate,\n",
        "    batchSize,\n",
        "    optimizer,\n",
        "    computeDevice,\n",
        "    # enableFeatureMode,\n",
        "    visualizer=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Trains a neural network model and evaluates it on test data.\n",
        "    \"\"\"\n",
        "    startTimestamp = time.time()\n",
        "    lossFunction = nn.MSELoss()\n",
        "\n",
        "    # if enableFeatureMode:\n",
        "    trainFeatures = transposeFeatureTensor(trainFeatures)\n",
        "    testFeatures = transposeFeatureTensor(testFeatures)\n",
        "\n",
        "    print(\"Training samples:\", trainFeatures.shape)\n",
        "    print(\"Training labels:\", len(trainTargets))\n",
        "    print(\"Testing samples:\", testFeatures.shape)\n",
        "    print(\"Testing labels:\", len(testTargets))\n",
        "    # else:\n",
        "    #     print(\"Training samples:\", trainFeatures.shape)\n",
        "    #     print(\"Training labels:\", len(trainTargets))\n",
        "    #     print(\"Testing samples:\", testFeatures.shape)\n",
        "    #     print(\"Testing labels:\", len(testTargets))\n",
        "\n",
        "    trainFeatures = trainFeatures.to(computeDevice)\n",
        "    trainTargets = trainTargets.to(computeDevice)\n",
        "    testFeatures = testFeatures.to(computeDevice)\n",
        "    testTargets = testTargets.to(computeDevice)\n",
        "\n",
        "    trainingSet = TensorDataset(trainFeatures, trainTargets)\n",
        "    trainingLoader = DataLoader(\n",
        "        trainingSet, batch_size=batchSize, shuffle=True\n",
        "    )\n",
        "\n",
        "    lrScheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer=optimizer,\n",
        "        max_lr=learningRate,\n",
        "        steps_per_epoch=len(trainingLoader),\n",
        "        epochs=numEpochs,\n",
        "        pct_start=0.3,\n",
        "        div_factor=25,\n",
        "    )\n",
        "\n",
        "    for epochIndex in range(numEpochs):\n",
        "        network.train()\n",
        "        batchLosses = []\n",
        "\n",
        "        for batchX, batchY in trainingLoader:\n",
        "            optimizer.zero_grad()\n",
        "            predictions = network(batchX)\n",
        "            batchLoss = lossFunction(\n",
        "                predictions.view(batchY.shape), batchY\n",
        "            )\n",
        "\n",
        "            batchLoss.backward()\n",
        "            optimizer.step()\n",
        "            lrScheduler.step()\n",
        "\n",
        "            batchLosses.append(batchLoss.detach().cpu().item())\n",
        "\n",
        "        if epochIndex == numEpochs - 1:\n",
        "            print(\"--\" * 20)\n",
        "            network.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputChunks = []\n",
        "                for chunk in generateBatches(testFeatures, batchSize=4096):\n",
        "                    outputChunks.append(\n",
        "                        # network(chunk, enableFeatureMode).detach()\n",
        "                        network(chunk).detach()\n",
        "                    )\n",
        "\n",
        "                fullPredictions = torch.concat(outputChunks, dim=0)\n",
        "                fullPredictions = fullPredictions.view(testTargets.shape)\n",
        "\n",
        "                mapeValue = computeMAPE(fullPredictions, testTargets)\n",
        "                rmseValue = computeRMSE(fullPredictions, testTargets)\n",
        "                r2Value = computeR2Score(fullPredictions, testTargets)\n",
        "\n",
        "                print(\n",
        "                    f\"Final Epoch {epochIndex}: \"\n",
        "                    f\"MAPE={mapeValue:.6f}, \"\n",
        "                    f\"RMSE={rmseValue:.6f}, \"\n",
        "                    f\"R2={r2Value:.6f}\"\n",
        "                )\n",
        "\n",
        "    elapsedTime = time.time() - startTimestamp\n",
        "\n",
        "    return elapsedTime, [\n",
        "        numEpochs,\n",
        "        mapeValue.cpu().numpy(),\n",
        "        rmseValue.cpu().numpy(),\n",
        "        r2Value.cpu().numpy(),\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uQJRrJ9ZlFp"
      },
      "outputs": [],
      "source": [
        "# model path\n",
        "modelRootDir = \"/content/CNN_LSTM_min_max_mean_std\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s9SKDGciliZ"
      },
      "source": [
        "### NOTE:\n",
        "\n",
        "**enableFeatureMode = True** → use statistical feature representation\n",
        "\n",
        "**enableFeatureMode = False** → use raw voltage representation (baseline method)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8NA4I02bMMn"
      },
      "outputs": [],
      "source": [
        "runBayesOpt = True\n",
        "bayesEpochs = 2\n",
        "# enableFeatureMode = True  # set runBayesOpt to False when loading saved results\n",
        "\n",
        "numFolds = 4\n",
        "\n",
        "# Load and prepare dataset\n",
        "datasetFile = \"Dataset_1_NCA_battery.xlsx\"\n",
        "batteryData = readDatasetFiles(datasetFile)\n",
        "\n",
        "cellPartitions = [\n",
        "    [11, 12, 28, 29, 30, 31, 32],\n",
        "    list(range(1, 11)) + list(range(13, 22)),\n",
        "    [22, 23, 24, 25, 26, 27, 33, 34, 35],\n",
        "    [36, 37, 38],\n",
        "    np.arange(39, 67),\n",
        "]\n",
        "\n",
        "samplesPerGroup = [1, 4, 2, 1, 6]  # stratified sampling plan\n",
        "\n",
        "randomSeed = 5\n",
        "rng = np.random.RandomState(seed=randomSeed)\n",
        "\n",
        "selectedTestCells = [\n",
        "    rng.choice(group, samplesPerGroup[idx], replace=False)\n",
        "    for idx, group in enumerate(cellPartitions)\n",
        "]\n",
        "selectedTestCells = [cell for group in selectedTestCells for cell in group]\n",
        "testCellKeys = selectedTestCells\n",
        "\n",
        "# Feature-based or raw-voltage-based data handling\n",
        "# if enableFeatureMode:\n",
        "trainFeatureMap, trainLabelMap, testFeatureMap, testLabelMap = (\n",
        "        splitCellsWithStats(batteryData, testCellIds=testCellKeys)\n",
        ")\n",
        "\n",
        "trainFeatures, testFeatures = scaleFeatureData(\n",
        "        trainFeatureMap, testFeatureMap\n",
        ")\n",
        "trainLabels = torch.cat(list(trainLabelMap.values()))\n",
        "shuffleIndices = np.arange(trainFeatures.shape[1])\n",
        "\n",
        "# else:\n",
        "#     trainFeatureMap, trainLabelMap, testFeatureMap, testLabelMap = (\n",
        "#         splitCells(batteryData, testCellIds=testCellKeys)\n",
        "#     )\n",
        "\n",
        "#     trainFeatures, testFeatures = scaleRawVoltageData(\n",
        "#         trainFeatureMap, testFeatureMap\n",
        "#     )\n",
        "#     trainLabels = torch.cat(list(trainLabelMap.values()))\n",
        "#     shuffleIndices = np.arange(trainFeatures.shape[0])\n",
        "\n",
        "# Shuffle training samples\n",
        "rng.shuffle(shuffleIndices)\n",
        "\n",
        "# if enableFeatureMode:\n",
        "trainFeatures = trainFeatures[:, shuffleIndices, :]\n",
        "trainLabels = trainLabels[shuffleIndices]\n",
        "# else:\n",
        "#     trainFeatures = trainFeatures[shuffleIndices]\n",
        "#     trainLabels = trainLabels[shuffleIndices]\n",
        "\n",
        "# Assemble test labels\n",
        "testLabels = torch.cat(list(testLabelMap.values()), dim=0)\n",
        "\n",
        "# Select computation device\n",
        "computeDevice = getAvailableDevice()\n",
        "\n",
        "# Model save location\n",
        "modelSaveDir = modelRootDir\n",
        "\n",
        "# Execute pipeline\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    message=\"The objective has been evaluated at this point before.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_kg5YxujIIn"
      },
      "source": [
        "Objective function used by Optuna for hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2h5M79AjH1C"
      },
      "outputs": [],
      "source": [
        "def optunaObjective(trial):\n",
        "    batchSize = trial.suggest_int(\"batchSize\", 32, 512, step=32)\n",
        "    learningRate = trial.suggest_float(\"learningRate\", 1e-5, 5e-2, log=True)\n",
        "    weightDecay = trial.suggest_float(\"weightDecay\", 1e-6, 1e-3, log=True)\n",
        "    epochCount = trial.suggest_int(\"epochCount\", 10, 11)\n",
        "    # epochCount = trial.suggest_int(\"epochCount\", 50, 150, step=10)\n",
        "    dropoutRate = trial.suggest_float(\"dropoutRate\", 0.001, 0.5, log=True)\n",
        "\n",
        "    accumulatedRmse = 0.0\n",
        "\n",
        "    for foldIdx in range(numFolds):\n",
        "        # if enableFeatureMode:\n",
        "        foldData = buildKFoldSplit(\n",
        "                numFolds, foldIdx, trainFeatures, trainLabels\n",
        "        )\n",
        "        # else:\n",
        "        #     foldData = buildKFoldSplit(\n",
        "        #         numFolds, foldIdx, trainFeatures, trainLabels\n",
        "        #     )\n",
        "\n",
        "        modelInstance = CNNModel(dropout=dropoutRate)\n",
        "        modelInstance = modelInstance.to(computeDevice)\n",
        "\n",
        "        decayParams = (\n",
        "            param\n",
        "            for name, param in modelInstance.named_parameters()\n",
        "            if not name.endswith(\"bias\") and \"bn\" not in name\n",
        "        )\n",
        "        noDecayParams = (\n",
        "            param\n",
        "            for name, param in modelInstance.named_parameters()\n",
        "            if name.endswith(\"bias\") or \"bn\" in name\n",
        "        )\n",
        "\n",
        "        optimizerParams = [\n",
        "            {\"params\": decayParams},\n",
        "            {\"params\": noDecayParams, \"weight_decay\": 0.0},\n",
        "        ]\n",
        "\n",
        "        optimizerInstance = torch.optim.Adam(\n",
        "            optimizerParams, lr=learningRate, weight_decay=weightDecay\n",
        "        )\n",
        "\n",
        "        _, metrics = trainNeuralNetwork(\n",
        "            modelInstance,\n",
        "            *foldData,\n",
        "            epochCount,\n",
        "            learningRate,\n",
        "            batchSize,\n",
        "            optimizerInstance,\n",
        "            computeDevice,\n",
        "            # enableFeatureMode,\n",
        "            visualizer=None,\n",
        "        )\n",
        "\n",
        "        accumulatedRmse += metrics[2]\n",
        "\n",
        "    return accumulatedRmse / numFolds\n",
        "\n",
        "\n",
        "# Executes Optuna optimization with the selected sampling strategy\n",
        "def executeOptunaSearch(trialCount, samplerType, objectiveFn, experimentName):\n",
        "    if samplerType == \"TPE\":\n",
        "        sampler = optuna.samplers.TPESampler(\n",
        "            n_startup_trials=10, n_ei_candidates=24\n",
        "        )\n",
        "    elif samplerType == \"GP\":\n",
        "        from optuna.integration import SkoptSampler\n",
        "\n",
        "        sampler = SkoptSampler(\n",
        "            skopt_kwargs={\n",
        "                \"base_estimator\": \"GP\",\n",
        "                \"n_initial_points\": 10,\n",
        "                \"acq_func\": \"EI\",\n",
        "            }\n",
        "        )\n",
        "    else:\n",
        "        sampler = None\n",
        "\n",
        "    study = optuna.create_study(\n",
        "        sampler=sampler,\n",
        "        direction=\"minimize\",\n",
        "        study_name=experimentName,\n",
        "    )\n",
        "\n",
        "    study.optimize(\n",
        "        objectiveFn,\n",
        "        n_trials=trialCount,\n",
        "        show_progress_bar=True,\n",
        "    )\n",
        "\n",
        "    joblib.dump(study, f\"{experimentName}.pkl\")\n",
        "\n",
        "    historyFigure = plot_optimization_history(study)\n",
        "    plotly.offline.plot(\n",
        "        historyFigure, filename=f\"{experimentName}.html\"\n",
        "    )\n",
        "\n",
        "    with open(f\"{experimentName}.txt\", \"w\") as outputFile:\n",
        "        print(\n",
        "            study.best_params,\n",
        "            study.best_value,\n",
        "            file=outputFile,\n",
        "        )\n",
        "\n",
        "    print(get_param_importances(study))\n",
        "\n",
        "    return study.best_trial.params, study.best_trial.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLC8KBaOk6K3"
      },
      "source": [
        "## Optimized parameter execution & extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "42abfd524c074ef298a8b9f393761a7e",
            "25f958635db04dcd96ce5a7d66c55222",
            "9dd2948df7d040df89136be6f8a6e5a9",
            "86f22afd3def4dfab1d8680972b22e27",
            "520fd1f1bfb74248932f0c77145739ae",
            "8439a39dec1c4b77a21236dc32d1289d",
            "c579fb7794214428af9ec904ef89bcf2",
            "14de6c7e8315424b99d61116d4e4b1d6",
            "d8f00c346aab4675822f89506ba53901",
            "18ea0599d99f4b58a9757169d7ae7f16",
            "04b43fd65d29475787a9624c31a4e7c9"
          ]
        },
        "id": "xH2ALzjgj9IX",
        "outputId": "bf44dce2-1baf-4851-a8de-a642c9aa2186"
      },
      "outputs": [],
      "source": [
        "if runBayesOpt:\n",
        "    optimalParams, optimalScore = executeOptunaSearch(\n",
        "        bayesEpochs,\n",
        "        \"TPE\",\n",
        "        optunaObjective,\n",
        "        modelRootDir,  # study identifier (experimentName)\n",
        "    )\n",
        "\n",
        "    print(f\"Optimal hyperparameters: {optimalParams}\")\n",
        "    print(f\"Optimal objective value: {optimalScore}\")\n",
        "\n",
        "    with open(\n",
        "        \"CNN_LSTM_best_params_min_max_mean_std.pkl\",\n",
        "        \"wb\",\n",
        "    ) as paramFile:\n",
        "        pickle.dump(optimalParams, paramFile)\n",
        "\n",
        "else:\n",
        "    with open(\n",
        "        \"CNN_LSTM_best_params_min_max_mean_std.pkl\",\n",
        "        \"rb\",\n",
        "    ) as paramFile:\n",
        "        optimalParams = pickle.load(paramFile)\n",
        "\n",
        "dropoutRate = optimalParams[\"dropoutRate\"]\n",
        "learningRate = optimalParams[\"learningRate\"]\n",
        "numEpochs = optimalParams[\"epochCount\"]\n",
        "batchSize = optimalParams[\"batchSize\"]\n",
        "\n",
        "trainingResults = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xTZp4Valgar"
      },
      "source": [
        "Model retraining with optimal hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ1P_niukyTl",
        "outputId": "d5469c0d-d9a7-4f7e-8db6-1a62a0699df1"
      },
      "outputs": [],
      "source": [
        "for runIndex in range(10):\n",
        "    # cnnModel = CNNModel(enableFeatureMode, dropoutRate)\n",
        "    cnnModel = CNNModel(dropoutRate)\n",
        "    cnnModel = cnnModel.to(computeDevice)\n",
        "\n",
        "    decayGroup = (\n",
        "        param\n",
        "        for name, param in cnnModel.named_parameters()\n",
        "        if not name.endswith(\"bias\") and \"bn\" not in name\n",
        "    )\n",
        "    noDecayGroup = (\n",
        "        param\n",
        "        for name, param in cnnModel.named_parameters()\n",
        "        if name.endswith(\"bias\") or \"bn\" in name\n",
        "    )\n",
        "\n",
        "    optimizerGroups = [\n",
        "        {\"params\": decayGroup},\n",
        "        {\"params\": noDecayGroup, \"weight_decay\": 0.0},\n",
        "    ]\n",
        "\n",
        "    optimizerInstance = torch.optim.Adam(\n",
        "        optimizerGroups,\n",
        "        learningRate,\n",
        "        weight_decay=optimalParams[\"weightDecay\"],\n",
        "    )\n",
        "\n",
        "    trainingTime, evalMetrics = trainNeuralNetwork(\n",
        "        cnnModel,\n",
        "        trainFeatures,\n",
        "        trainLabels,\n",
        "        testFeatures,\n",
        "        testLabels,\n",
        "        numEpochs,\n",
        "        learningRate,\n",
        "        batchSize,\n",
        "        optimizerInstance,\n",
        "        computeDevice,\n",
        "        # enableFeatureMode,\n",
        "        visualizer=None,\n",
        "    )\n",
        "\n",
        "    inferenceStart = time.time()\n",
        "\n",
        "    # if enableFeatureMode:\n",
        "    print(testFeatures.shape)\n",
        "\n",
        "    reorderedTestX = testFeatures.permute(1, 2, 0)\n",
        "    print(reorderedTestX.shape)\n",
        "\n",
        "    inferenceOutputs = [\n",
        "            cnnModel(\n",
        "                sample.reshape(1, 4, 14)\n",
        "                # , enableFeatureMode,\n",
        "            )\n",
        "            for sample in reorderedTestX[:1000].to(computeDevice)\n",
        "    ]\n",
        "    # else:\n",
        "    #     inferenceOutputs = [\n",
        "    #         cnnModel(\n",
        "    #             sample.reshape(1, 14)\n",
        "    #             # , enableFeatureMode,\n",
        "    #         )\n",
        "    #         for sample in testFeatures[:1000].to(computeDevice)\n",
        "    #     ]\n",
        "\n",
        "    inferenceEnd = time.time()\n",
        "\n",
        "    avgInferenceTime = (\n",
        "        inferenceEnd - inferenceStart\n",
        "    ) / len(testFeatures[:1000])\n",
        "\n",
        "    trainingResults.append([trainingTime, avgInferenceTime])\n",
        "\n",
        "    print([trainingTime, avgInferenceTime])\n",
        "\n",
        "trainingResults = np.array(trainingResults)\n",
        "\n",
        "print(\n",
        "    \"Mean training duration for CNN:\",\n",
        "    np.mean(trainingResults[:, 0]),\n",
        ")\n",
        "print(\n",
        "    \"Mean inference duration:\",\n",
        "    np.mean(trainingResults[:, 1]),\n",
        ")\n",
        "\n",
        "os.makedirs(\"/content/model_save\", exist_ok=True)\n",
        "\n",
        "torch.save(\n",
        "    cnnModel.state_dict(),\n",
        "    f\"/content/model_save/{modelRootDir.split(\"/\")[2]}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lujLPm36lkA9"
      },
      "source": [
        "## Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "pO-WvQMPllK2",
        "outputId": "28487f90-c9b9-4bae-b12f-d5328d1f1f95"
      },
      "outputs": [],
      "source": [
        "# Display average training and evaluation metrics\n",
        "print(f'Average training duration: {trainingTime:.6f} s')\n",
        "print(f'Test Set -> MAPE: {evalMetrics[1]:.6f}, RMSE: {evalMetrics[2]:.6f}, R2: {evalMetrics[3]:.6f}')\n",
        "\n",
        "# Create subplots for visualizing individual battery predictions\n",
        "# fig, axes = plt.subplots(3, 4, figsize=(17, 13))\n",
        "fig, axes = plt.subplots(2, 5, figsize=(17, 13))\n",
        "axes = axes.flat\n",
        "\n",
        "# Load the trained model\n",
        "cnnModel.load_state_dict(torch.load(f'model_save/{modelRootDir.split(\"/\")[2]}', weights_only=True))\n",
        "cnnModel.eval()\n",
        "\n",
        "predictionsDict = {}\n",
        "scatterPred, scatterTrue = [], []\n",
        "\n",
        "print('--' * 20)\n",
        "\n",
        "with torch.no_grad():\n",
        "    batteryKeys = list(testXDict.keys())\n",
        "    selectedKeys = np.random.choice(batteryKeys, len(axes), replace=False)\n",
        "\n",
        "    for idx, key in enumerate(selectedKeys):\n",
        "        sampleX = testXDict[key]\n",
        "        reshapedX = transposeFeatureTensor(sampleX).to(computeDevice) # if enableFeatureMode else sampleX.to(computeDevice)\n",
        "\n",
        "        # predictedY = cnnModel(reshapedX, enableFeatureMode).detach().cpu()\n",
        "        predictedY = cnnModel(reshapedX).detach().cpu()\n",
        "        scatterPred.extend(predictedY.numpy())\n",
        "        scatterTrue.extend(testYDict[key].cpu().numpy())\n",
        "\n",
        "        mapeScore = computeMAPE(predictedY, testYDict[key])\n",
        "        rmseScore = computeRMSE(predictedY, testYDict[key])\n",
        "        r2Score = computeR2Score(predictedY, testYDict[key])\n",
        "\n",
        "        print(f'Battery {key} -> MAPE: {mapeScore:.6f}, RMSE: {rmseScore:.6f}, R2: {r2Score:.6f}')\n",
        "        predictionsDict[key] = predictedY.numpy()\n",
        "\n",
        "        cycleRange = np.arange(len(testYDict[key]))\n",
        "        axes[idx].plot(cycleRange, testYDict[key], label='True SOH', linewidth=1, marker='+', markersize=1, zorder=1)\n",
        "        axes[idx].plot(cycleRange, predictionsDict[key], label='Predicted SOH', linewidth=1, marker='_', markersize=1, zorder=1)\n",
        "\n",
        "        rateLabel = str(round(float(key[2:key[2:].find(\"_\")]), 2))\n",
        "        tempLabel = key[key.rfind(\"_\") - 2:key.rfind(\"_\")]\n",
        "        cellLabel = key[key.rfind(\"_\") + 1:]\n",
        "        axes[idx].set_title(f\"NCA_{rateLabel}_{tempLabel} #{cellLabel}\")\n",
        "\n",
        "        if idx % 4 == 0:\n",
        "            axes[idx].set_ylabel('SOH')\n",
        "        if idx >= 8:\n",
        "            axes[idx].set_xlabel('Cycle Number')\n",
        "        axes[idx].legend(loc='upper right')\n",
        "\n",
        "# Scatter plot of predictions vs. true SOH using logarithmic color scale for error\n",
        "scatterPred, scatterTrue = np.array(scatterPred), np.array(scatterTrue)\n",
        "predictionErrors = np.abs(scatterPred - scatterTrue)\n",
        "\n",
        "scatterPlot = plt.scatter(\n",
        "    scatterPred,\n",
        "    scatterTrue,\n",
        "    c=predictionErrors,\n",
        "    cmap=\"viridis\",\n",
        "    norm=LogNorm(vmin=1e-4, vmax=1e-1),\n",
        "    s=3,\n",
        "    zorder=2,\n",
        ")\n",
        "\n",
        "colorBar = plt.colorbar(scatterPlot, ticks=[1e-4, 1e-3, 1e-2, 1e-1])\n",
        "colorBar.set_label('Prediction Error', labelpad=10)\n",
        "colorBar.ax.yaxis.set_major_formatter(ticker.LogFormatterMathtext())\n",
        "\n",
        "plt.plot([0.7, 1], [0.7, 1], '--', color='gold', linewidth=2, label='Real SOH', zorder=1)\n",
        "plt.xlim([0.7, 1])\n",
        "plt.ylim([0.7, 1])\n",
        "plt.xlabel(\"Actual SOH\")\n",
        "plt.ylabel(\"Predicted SOH\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0SyJRLhnz5D"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S94qUwyRn0MZ"
      },
      "outputs": [],
      "source": [
        "numFeatures = 3 # #CHANGE NUMBER OF FEATURES, CREATE num_features\n",
        "modelSaveDir = \"/content/New_CNN_GRU_min_max_mean\"\n",
        "tlModelPath = \"/content/New_CNN_GRU_min_max_mean_TL_DS2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trRRNXLnpFXA"
      },
      "source": [
        "#### Function Definition\n",
        "\n",
        "**computeL2Loss:** Computes L2 distance between two model state dictionaries, ignoring batch-norm and tracking parameters.\n",
        "\n",
        "**fineTuneModel:** Fine-tunes a model using a combination of prediction loss and L2 regularization toward a source model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CGV_nTroB7R"
      },
      "outputs": [],
      "source": [
        "def computeL2Loss(paramSetA, paramSetB):\n",
        "    \"\"\"\n",
        "    Computes L2 distance between two model state dictionaries, ignoring batch-norm and tracking parameters.\n",
        "    \"\"\"\n",
        "    totalLoss = 0\n",
        "    for key in paramSetA.keys():\n",
        "        if 'running_mean' in key or 'running_var' in key or 'num_batches_tracked' in key:\n",
        "            continue\n",
        "        diff = paramSetA[key] - paramSetB[key]\n",
        "        totalLoss += torch.sum(diff ** 2)\n",
        "    return totalLoss\n",
        "\n",
        "def fineTuneModel(model, trainX, trainY, testX, testY, epochs, learningRate, batchSize, optimizer, device, sourceParams, lambdaReg=0.05):\n",
        "    \"\"\"\n",
        "    Fine-tunes a model using a combination of prediction loss and L2 regularization toward a source model.\n",
        "    \"\"\"\n",
        "    startTime = time.time()\n",
        "    mseLoss = nn.MSELoss()\n",
        "\n",
        "    # Reshape features if using statistical features\n",
        "    trainX = transposeFeatureTensor(trainX)\n",
        "    testX = transposeFeatureTensor(testX)\n",
        "    print(\"Train Data Shape:\", len(trainX), len(trainX[0]), len(trainX[0][0]))\n",
        "    print(\"Train Labels Shape:\", len(trainY))\n",
        "    print(\"Test Data Shape:\", len(testX), len(testX[0]), len(testX[0][0]))\n",
        "    print(\"Test Labels Shape:\", len(testY))\n",
        "\n",
        "    # Move tensors to device\n",
        "    trainX, trainY = trainX.to(device), trainY.to(device)\n",
        "    testX, testY = testX.to(device), testY.to(device)\n",
        "\n",
        "    # Prepare DataLoader\n",
        "    trainDataset = TensorDataset(trainX, trainY)\n",
        "    trainLoader = DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learningRate,\n",
        "        steps_per_epoch=len(trainLoader),\n",
        "        epochs=epochs,\n",
        "        pct_start=0.3,\n",
        "        div_factor=25\n",
        "    )\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epochLosses = []\n",
        "        model.train()\n",
        "        for batchX, batchY in trainLoader:\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(batchX)\n",
        "            l2RegLoss = computeL2Loss(sourceParams, model.state_dict())\n",
        "            totalLoss = mseLoss(predictions.reshape(batchY.shape), batchY) + lambdaReg * l2RegLoss\n",
        "            epochLosses.append(totalLoss.detach().cpu().numpy())\n",
        "            totalLoss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        # Evaluate on the last epoch\n",
        "        if epoch == epochs - 1:\n",
        "            print('--' * 20)\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                if testX.shape[1] != numFeatures:\n",
        "                    testX = testX.reshape(len(testX[0]), len(testX), len(testX[0][0]))\n",
        "                predictedY = [model(x).detach() for x in generateBatches(testX, batchSize=4096)]\n",
        "                predictedY = torch.concat(predictedY, dim=0).reshape(testY.shape)\n",
        "\n",
        "                mapeScore = computeMAPE(predictedY, testY)\n",
        "                rmseScore = computeRMSE(predictedY, testY)\n",
        "                r2Score = computeR2Score(predictedY, testY)\n",
        "\n",
        "                print(f'Test Epoch {epoch} -> MAPE: {mapeScore:.6f}, RMSE: {rmseScore:.6f}, R2: {r2Score:.6f}')\n",
        "\n",
        "    endTime = time.time()\n",
        "    return endTime - startTime, [epochs, mapeScore.cpu().numpy(), rmseScore.cpu().numpy(), r2Score.cpu().numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjsdsvrOpBkN",
        "outputId": "cb1ddaa7-adee-4cb6-dcfe-3c7fb28841a0"
      },
      "outputs": [],
      "source": [
        "needBo, boEpochs = False, 50\n",
        "savePath = tlModelPath  # Path to save/load TL model\n",
        "randomSeed = 10\n",
        "performTransferLearning = True\n",
        "datasetPath = r'/content/dataset2/Dataset_2_NCM_battery.xlsx'\n",
        "\n",
        "# Load battery dataset containing voltage, current, and SOH (labels)\n",
        "batteryData = readDatasetFiles(datasetPath)\n",
        "\n",
        "# Define cell groups and stratified sampling parameters\n",
        "cellGroups = [np.arange(1, 24), np.arange(24, 28), np.arange(28, 56)]\n",
        "samplesPerGroup, samplingStep = [6, 1, 3], 10\n",
        "\n",
        "# Generate stratified training cell list\n",
        "trainCellsList = [np.random.RandomState(seed=randomSeed).choice(group, samplesPerGroup[i], replace=False)\n",
        "                  for i, group in enumerate(cellGroups)]\n",
        "trainCells = [cell for sublist in trainCellsList for cell in sublist]\n",
        "\n",
        "# Split dataset into training and testing sets, using statistical features if enabled\n",
        "trainXDict, trainYDict, testXDict, testYDict = splitCellsWithStats(batteryData, testCellIds=trainCells)\n",
        "trainX, testX = scaleFeatureData(trainXDict, testXDict)\n",
        "trainY = torch.cat([y for y in trainYDict.values()])\n",
        "indices = np.arange(len(trainX[0]))\n",
        "\n",
        "# Display dataset shapes\n",
        "print(\"Training data shape:\", len(trainX), len(trainX[0]), len(trainX[0][0]))\n",
        "print(\"Testing data shape:\", len(testX), len(testX[0]), len(testX[0][0]))\n",
        "\n",
        "# Apply random shuffling and sparse sampling if using features\n",
        "np.random.RandomState(seed=randomSeed).shuffle(indices)\n",
        "trainX, trainY = trainX[:, indices[::samplingStep], :], trainY[indices[::samplingStep]]\n",
        "\n",
        "# Optional second shuffling for added randomness\n",
        "indices = np.arange(len(trainX[0]))\n",
        "np.random.RandomState(seed=randomSeed).shuffle(indices)\n",
        "trainX, trainY = trainX[:, indices, :], trainY[indices]\n",
        "\n",
        "# Concatenate test labels\n",
        "testY = torch.cat([y for y in testYDict.values()], dim=0)\n",
        "\n",
        "# Move data to GPU if available\n",
        "device = getAvailableDevice()\n",
        "\n",
        "# Load pre-trained model for transfer learning\n",
        "pretrainedParams = torch.load(f'/content/model_save/{modelRootDir.split(\"/\")[2]}')  # Map to GPU if needed"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04b43fd65d29475787a9624c31a4e7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14de6c7e8315424b99d61116d4e4b1d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ea0599d99f4b58a9757169d7ae7f16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25f958635db04dcd96ce5a7d66c55222": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8439a39dec1c4b77a21236dc32d1289d",
            "placeholder": "​",
            "style": "IPY_MODEL_c579fb7794214428af9ec904ef89bcf2",
            "value": "Best trial: 0. Best value: 0.0244575: 100%"
          }
        },
        "42abfd524c074ef298a8b9f393761a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25f958635db04dcd96ce5a7d66c55222",
              "IPY_MODEL_9dd2948df7d040df89136be6f8a6e5a9",
              "IPY_MODEL_86f22afd3def4dfab1d8680972b22e27"
            ],
            "layout": "IPY_MODEL_520fd1f1bfb74248932f0c77145739ae"
          }
        },
        "520fd1f1bfb74248932f0c77145739ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8439a39dec1c4b77a21236dc32d1289d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f22afd3def4dfab1d8680972b22e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18ea0599d99f4b58a9757169d7ae7f16",
            "placeholder": "​",
            "style": "IPY_MODEL_04b43fd65d29475787a9624c31a4e7c9",
            "value": " 2/2 [06:01&lt;00:00, 169.95s/it]"
          }
        },
        "9dd2948df7d040df89136be6f8a6e5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14de6c7e8315424b99d61116d4e4b1d6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8f00c346aab4675822f89506ba53901",
            "value": 2
          }
        },
        "c579fb7794214428af9ec904ef89bcf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8f00c346aab4675822f89506ba53901": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
